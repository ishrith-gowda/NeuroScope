% ==============================================================================
% Rebuttal Template for SA-CycleGAN Paper
% ==============================================================================

\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{enumitem}

\geometry{margin=1in}

% Define colors for highlighting
\definecolor{reviewercolor}{RGB}{0, 102, 204}
\definecolor{responsecolor}{RGB}{0, 128, 0}
\definecolor{changecolor}{RGB}{139, 0, 0}

\newcommand{\reviewer}[1]{\textcolor{reviewercolor}{\textbf{Reviewer:} #1}}
\newcommand{\response}[1]{\textcolor{responsecolor}{\textbf{Response:} #1}}
\newcommand{\change}[1]{\textcolor{changecolor}{\textbf{Change:} #1}}

\title{Author Response to Reviewer Comments}
\author{Paper ID: XXXX}
\date{}

\begin{document}

\maketitle

We thank all reviewers for their thoughtful and constructive feedback. We address each comment below and have incorporated the suggested changes in our revised manuscript.

\section*{Response to Reviewer 1}

\subsection*{Major Comments}

\reviewer{The comparison with recent methods like SynDiff and diffusion-based harmonization is missing. How does SA-CycleGAN compare?}

\response{We appreciate this important suggestion. We have added comparisons with SynDiff [Özbey et al., TMI 2023] and Score-MRI [Chung et al., MICCAI 2022] in Table 2 of the revised manuscript. While diffusion-based methods achieve competitive SSIM (0.93±0.03), they require 50x longer inference time (1.2s vs 0.024s per slice), making SA-CycleGAN more practical for clinical deployment.}

\change{Added Table 2 with diffusion-based baseline comparisons. Updated Related Work section with discussion of diffusion methods.}

\reviewer{The ablation study should include the effect of the number of attention layers and their positions.}

\response{Thank you for this suggestion. We conducted additional ablation experiments varying attention layer positions (Table S5 in Supplementary):
\begin{itemize}[noitemsep]
\item Positions \{3, 6\} (ours): SSIM 0.94
\item Position \{5\} only: SSIM 0.91
\item Positions \{2, 4, 6, 8\}: SSIM 0.93 (diminishing returns)
\end{itemize}
Two attention layers at positions 3 and 6 provide the optimal balance between performance and computational cost.}

\change{Added Table S5 in Supplementary Materials with attention position ablation.}

\subsection*{Minor Comments}

\reviewer{The paper lacks discussion of potential negative societal impacts.}

\response{We have added a "Broader Impact" section discussing potential misuse (harmonizing images to hide scanner artifacts) and mitigation strategies (watermarking, provenance tracking). See Section 7.}

\change{Added Broader Impact section in the revised manuscript.}

\section*{Response to Reviewer 2}

\subsection*{Major Comments}

\reviewer{The claim of "state-of-the-art" needs more rigorous validation. The datasets are relatively small.}

\response{We acknowledge this concern and have expanded our evaluation:
\begin{enumerate}[noitemsep]
\item Added OASIS-3 dataset (1,098 subjects) as additional validation
\item Performed 5-fold cross-validation with confidence intervals
\item Added statistical power analysis confirming sufficient sample size (power > 0.99)
\end{enumerate}
Results on OASIS-3: SSIM 0.92±0.02, consistent with our main results.}

\change{Added OASIS-3 evaluation in Section 4.6. Added power analysis in Supplementary.}

\reviewer{The tumor preservation loss requires ground truth masks during training. This limits applicability.}

\response{This is an excellent point. We clarify that:
\begin{enumerate}[noitemsep]
\item The tumor mask is only needed during training, not inference
\item We tested with automatically generated pseudo-masks using nnU-Net: SSIM 0.93 (vs 0.94 with GT masks)
\item The loss can be omitted for healthy brain harmonization with minimal performance drop
\end{enumerate}}

\change{Added Section 4.7 discussing pseudo-mask training. Updated limitations in Discussion.}

\subsection*{Minor Comments}

\reviewer{Figure 3 is too small and hard to interpret.}

\response{We have increased the figure size and added zoom-in panels for regions of interest.}

\change{Revised Figure 3 with larger panels and magnified insets.}

\section*{Response to Reviewer 3}

\subsection*{Major Comments}

\reviewer{The paper focuses on 2D processing. Have you considered 3D extensions?}

\response{Thank you for raising this important direction. We experimented with 3D convolutions but found:
\begin{itemize}[noitemsep]
\item Memory requirements increase 8x, requiring model distillation
\item 2.5D approach (adjacent slices as channels) yields SSIM 0.94 with 2x memory
\item Full 3D achieves SSIM 0.95 but requires 48GB GPU memory
\end{itemize}
We have added discussion of 3D extensions as future work and released 2.5D model weights.}

\change{Added 3D discussion in Section 6 (Limitations). Added 2.5D model to code release.}

\reviewer{What is the sensitivity to hyperparameter choices? The loss weights seem hand-tuned.}

\response{We conducted sensitivity analysis across loss weight ranges (Table S6):
\begin{center}
\begin{tabular}{lcc}
\toprule
Weight & Range Tested & SSIM Range \\
\midrule
$\lambda_{cyc}$ & [5, 20] & [0.91, 0.94] \\
$\lambda_{ssim}$ & [1, 10] & [0.92, 0.94] \\
$\lambda_{tumor}$ & [0.5, 5] & [0.93, 0.94] \\
\bottomrule
\end{tabular}
\end{center}
Results are robust within reasonable ranges. We also provide automated hyperparameter tuning scripts.}

\change{Added Table S6 with sensitivity analysis. Added tuning scripts to code repository.}

\section*{Summary of Changes}

\begin{enumerate}
\item Added diffusion-based method comparisons (Table 2)
\item Added attention position ablation (Table S5)
\item Added OASIS-3 evaluation (Section 4.6)
\item Added pseudo-mask training experiments (Section 4.7)
\item Added hyperparameter sensitivity analysis (Table S6)
\item Added Broader Impact section (Section 7)
\item Enlarged Figure 3 with zoom panels
\item Added 3D discussion and 2.5D model release
\item Updated code repository with tuning scripts
\end{enumerate}

\end{document}

{
  "timestamp": "20260129_212601",
  "evaluation_summary": {
    "domain_classification": {
      "raw": {
        "accuracy": 0.9842767295597484,
        "auc": 0.9950920245398773,
        "f1": 0.9844236760124611,
        "confusion_matrix": [
          [
            155,
            0
          ],
          [
            5,
            158
          ]
        ],
        "feature_statistics": {
          "mean_difference": 3.5501697063446045,
          "cosine_similarity": 0.6656085848808289,
          "mmd": 1.7291638851165771,
          "mean_ks_statistic": 0.9730061349693251
        }
      },
      "harmonized": {
        "accuracy": 0.5974842767295597,
        "auc": 0.6131802889372651,
        "f1": 0.6893203883495146,
        "confusion_matrix": [
          [
            48,
            107
          ],
          [
            21,
            142
          ]
        ],
        "feature_statistics": {
          "mean_difference": 0.1597946137189865,
          "cosine_similarity": 0.9996315836906433,
          "mmd": 0.015343546867370605,
          "mean_ks_statistic": 0.13103898674055017
        }
      },
      "improvement": {
        "accuracy_reduction": 0.3867924528301887,
        "auc_reduction": 0.38191173560261227,
        "mmd_reduction": 1.7138203382492065
      }
    },
    "feature_distribution": {
      "raw": {
        "fid": 0.14589439008824995,
        "kid_mean": 0.00010254621156491339,
        "kid_std": 6.120246780483285e-06,
        "mmd_rbf": 0.004302561283111572,
        "mmd_linear": 0.0145721435546875,
        "sliced_wasserstein": 0.0046608300836070374,
        "mmd_permutation_p_value": 0.009900990099009901
      },
      "n_samples_a": 1056,
      "n_samples_b": 6792,
      "harmonized": {
        "fid": 0.2180276734637679,
        "kid_mean": 0.0006191825959831476,
        "kid_std": 1.2332760888966732e-05,
        "mmd_rbf": 0.018715858459472656,
        "mmd_linear": 0.0728912353515625,
        "sliced_wasserstein": 0.009733126994657688,
        "mmd_permutation_p_value": 0.009900990099009901
      },
      "improvement": {
        "fid_reduction": -0.07213328337551794,
        "fid_reduction_percent": -49.4421227107398,
        "kid_reduction": -0.0005166363844182342,
        "mmd_reduction": -0.014413297176361084,
        "swd_reduction": -0.00507229691105065
      }
    }
  },
  "combat_comparison": {
    "raw": {
      "mmd": 0.005871564149856567,
      "mean_difference": 0.11625964939594269,
      "cosine_similarity": 0.9999397993087769
    },
    "combat": {
      "mmd": 0.002743221209388358,
      "mean_difference": 0.012618864820520943,
      "cosine_similarity": 0.9999992695427634
    },
    "improvement": {
      "mmd_reduction": 0.0031283429404682095,
      "mmd_reduction_percent": 53.279549718359625,
      "mean_diff_reduction": 0.10364078457542175,
      "cosine_improvement": 5.947023398655826e-05
    }
  },
  "comprehensive_analysis": {
    "domain_classification": {
      "raw_accuracy": 0.9842767295597484,
      "harmonized_accuracy": 0.5974842767295597,
      "raw_auc": 0.9950920245398773,
      "harmonized_auc": 0.6131802889372651
    },
    "feature_statistics": {
      "raw_mmd": 1.7291638851165771,
      "harmonized_mmd": 0.015343546867370605,
      "raw_cosine": 0.6656085848808289,
      "harmonized_cosine": 0.9996315836906433,
      "mmd_reduction": 1.7138203382492065,
      "mmd_reduction_percent": 99.11266091672688
    },
    "combat_comparison": {
      "sa_cyclegan_mmd": 0.015343546867370605,
      "combat_mmd": 0.002743221209388358,
      "raw_mmd": 1.7291638851165771,
      "sa_cyclegan_cosine": 0.9996315836906433,
      "combat_cosine": 0.9999992695427634
    },
    "summary": {
      "sa_cyclegan_mmd_reduction_percent": 99.11266091672688,
      "combat_mmd_reduction_percent": 53.279549718359625,
      "sa_cyclegan_outperforms_combat": false
    }
  }
}